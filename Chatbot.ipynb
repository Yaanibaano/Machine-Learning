{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"Chatbot.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Hu3yMgejN48o","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"DjqSTSpsN7jR","colab_type":"text"},"source":["# **Importing the necessary Libraries**"]},{"cell_type":"code","metadata":{"id":"bVLgWHsx8xsL","colab_type":"code","outputId":"f9d4f4a2-c46d-464f-fc1e-d9a11db40786","executionInfo":{"status":"ok","timestamp":1585305645251,"user_tz":-330,"elapsed":1108,"user":{"displayName":"chandru vijayan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcqqI9Vzqn9Wr4C1Buu09yCaM0V0Ef4_p5JY6M=s64","userId":"15479585662750339455"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense,CuDNNLSTM,Dropout,Dense,LSTM\n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer\n","from tensorflow.keras.layers import Embedding\n","import sklearn\n","import nltk\n","from sklearn.model_selection import train_test_split\n","nltk.download(\"punkt\")\n","from gensim.models import Word2Vec,KeyedVectors;"],"execution_count":31,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TRzaoMmRNh15","colab_type":"text"},"source":["#**Loading the Data** "]},{"cell_type":"code","metadata":{"id":"rSGCgIqk_-6S","colab_type":"code","colab":{}},"source":["data = pd.read_csv(\"All-seasons.csv\")\n","# print(data.head())\n","lines = data[\"Line\"]\n","# print(lines.head())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KC3DXvFDOU6p","colab_type":"text"},"source":["# **Cleaning the Text**"]},{"cell_type":"code","metadata":{"id":"wpfQUkmJp6D_","colab_type":"code","colab":{}},"source":["import re\n","\n","def clean(text):\n","  text = text.lower()   \n","  text = re.sub(r\"\\n\", \"\",  text)\n","  text = re.sub(r\"[-()]\", \"\", text)\n","  text = re.sub(r\"\\.\", \" .\", text)\n","  text = re.sub(r\"\\!\", \" !\", text)\n","  text = re.sub(r\"\\?\", \" ?\", text)\n","  text = re.sub(r\"\\,\", \" ,\", text)\n","  text = re.sub(r\"i'm\", \"i am\", text)\n","  text = re.sub(r\"he's\", \"he is\", text)\n","  text = re.sub(r\"she's\", \"she is\", text)\n","  text = re.sub(r\"it's\", \"it is\", text)\n","  text = re.sub(r\"that's\", \"that is\", text)\n","  text = re.sub(r\"what's\", \"that is\", text)\n","  text = re.sub(r\"\\'ll\", \" will\", text)\n","  text = re.sub(r\"\\'re\", \" are\", text)\n","  text = re.sub(r\"won't\", \"will not\", text)\n","  text = re.sub(r\"can't\", \"cannot\", text)\n","  text = re.sub(r\"n't\", \" not\", text)\n","  text = re.sub(r\"n'\", \"ng\", text)\n","  text = re.sub(r\"ohh\", \"oh\", text)\n","  text = re.sub(r\"ohhh\", \"oh\", text)\n","  text = re.sub(r\"ohhhh\", \"oh\", text)\n","  text = re.sub(r\"ohhhhh\", \"oh\", text)\n","  text = re.sub(r\"ohhhhhh\", \"oh\", text)\n","  text = re.sub(r\"ahh\", \"ah\", text)\n","  return text\n","clean_text = []\n","for i in lines:\n","    clean_text.append(clean(i))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uDpjRnfAObSZ","colab_type":"text"},"source":["# **Preprocessing the text(converting words to vectors)**"]},{"cell_type":"code","metadata":{"id":"uU0RnnZjswNx","colab_type":"code","colab":{}},"source":["tokenized_text = []\n","for line in clean_text:\n","  tokenized_text.append(nltk.word_tokenize(line))\n","tokenized_text = np.array(tokenized_text)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OAmJJPJ1Sp3g","colab_type":"code","colab":{}},"source":["# word embedding\n","word_embedding_model = Word2Vec(tokenized_text,min_count=1,size=300)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E6BcqHK7PqZq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":74},"outputId":"5d381351-7675-4ebb-85e7-9f8e6534779f","executionInfo":{"status":"ok","timestamp":1585303250599,"user_tz":-330,"elapsed":6662,"user":{"displayName":"chandru vijayan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcqqI9Vzqn9Wr4C1Buu09yCaM0V0Ef4_p5JY6M=s64","userId":"15479585662750339455"}}},"source":["tokenized_vector = []\n","for sentences in tokenized_text:\n","  sentence_vector = [word_embedding_model[w] for w in sentences]\n","  tokenized_vector.append(sentence_vector)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ZkZyvoscU5it","colab_type":"code","colab":{}},"source":["padding_vector = np.zeros(300)\n","# print(padding_vector.shape)\n","\n","#function to remove list/sentences above 30 words\n","def max30(listy):\n","  if len(listy) > 30:\n","    return False\n","  else:\n","    return True\n","\n","#function to pad lists/sentences with (300,1) zero array if len is smaller than 30\n","def pad30(listy):\n","  if len(listy)!=30:\n","    diff = 30-len(listy)\n","    for i in range(diff):\n","      listy.append(padding_vector)\n","    return np.array(listy)\n","  else:\n","    return np.array(listy)\n","\n","short_vectors = []\n","short_vectors = list(filter(max30,tokenized_vector))\n","\n","#padded vectors is a (n,30,300) array\n","padded_vectors = np.array(list(map(pad30,short_vectors)),dtype=np.float64)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j6zVb7bdaH9d","colab_type":"text"},"source":["# **Test train Split**"]},{"cell_type":"code","metadata":{"id":"yPYnnbGWXntZ","colab_type":"code","colab":{}},"source":["vec_x = padded_vectors[1:]\n","vec_y = padded_vectors[:-1]\n","x_train,x_test,y_train,y_test = train_test_split(vec_x,vec_y,test_size=0.2,random_state=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UW1XyTBWhhtW","colab_type":"text"},"source":["# **Model Training and Testing**"]},{"cell_type":"code","metadata":{"id":"YMcefAVHalbM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":93},"outputId":"1ffc5a5a-123d-43ce-bcbd-df49cc40aaf3","executionInfo":{"status":"ok","timestamp":1585303918097,"user_tz":-330,"elapsed":2264,"user":{"displayName":"chandru vijayan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjcqqI9Vzqn9Wr4C1Buu09yCaM0V0Ef4_p5JY6M=s64","userId":"15479585662750339455"}}},"source":["model=Sequential()\n","model.add(LSTM(300,input_shape=x_train.shape[1:],return_sequences=True, activation='sigmoid'))\n","model.add(LSTM(300,input_shape=x_train.shape[1:],return_sequences=True, activation='sigmoid'))\n","model.add(LSTM(300,input_shape=x_train.shape[1:],return_sequences=True, activation='sigmoid'))\n","model.add(LSTM(300,input_shape=x_train.shape[1:],return_sequences=True, activation='sigmoid'))\n","model.compile(loss='cosine_proximity', optimizer='adam', metrics=['accuracy'])"],"execution_count":17,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IKUGyl3Uepbp","colab_type":"code","colab":{}},"source":["model.fit(x_train, y_train, nb_epoch=2000,validation_data=(x_test, y_test))\n","predict = model.predict(x_test)\n","c = [word_embedding_model.most_similar([predict[10][i]])[0] for i in range(30)]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bqh0qpZ4hrzi","colab_type":"text"},"source":["# **User interacton**"]},{"cell_type":"code","metadata":{"id":"An76KQXDhaqR","colab_type":"code","colab":{}},"source":["input_sentence = input(\"enter an sentence\")\n","input_tokenized = nltk.tokenize(input_sentence)\n","embedded_input = [word_embedding_model[w] for w in input_tokenized]\n","if len(embedded_input)>30:\n","  embedded_input[29:] = [] \n","elif len(embedded_input)<30:\n","  diff = 30-len(embedded_input)\n","  for i in range(diff):\n","    embedded_input.append(padding_vector)\n","embedded_input = embedded_input.reshape(1,30,300)\n","predicted = model.predic(embedded_input)\n","output = [word_embedding_model.most_similar(i) for i in predicted]\n","output_string = \" \".join(output)"],"execution_count":0,"outputs":[]}]}